[{"question_id": 1, "language": "python", "file_name": "solution.py", "question": "import torch.nn as nn\n\nclass LinearRegression(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n\n    def forward(self, x):\n        \"\"\"\n        完成二元回归的前向传播过程\n\n        输入:\n        - x: 一个形状为(batch_size, input_size)的PyTorch张量。\n\n        输出:\n        - out: 一个形状为(batch_size, output_size)的PyTorch张量，表示线性回归模型的输出。\n        \"\"\"\n         # TODO: 完成这个函数", "reference": "import torch.nn as nn\n\nclass LinearRegression(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(LinearRegression, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n\n    def forward(self, x):\n        \"\"\"\n        输入:\n        - x: 一个形状为(batch_size, input_size)的PyTorch张量。1111\n\n        输出:\n        - out: 一个形状为(batch_size, output_size)的PyTorch张量，表示线性回归模型的输出。\n        \"\"\"\n        out = self.linear(x)\n        return out", "main": "import torch\nimport torch.nn as nn\nimport numpy as np\nfrom solution import LinearRegression\n\ndef main():\n    # 定义模型\n    input_dim = 1  # 输入的维度\n    output_dim = 1  # 输出的维度\n\n    model = LinearRegression(input_dim, output_dim)\n\n    # 定义损失函数和优化器\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n\n    # 训练模型\n    epochs = 100\n    # 数据集\n    np.random.seed(0)\n    x = np.random.rand(10, 1)\n    y = 2 * x + 3 + np.random.randn(10, 1)\n\n    # 将numpy数组转换为PyTorch Tensor\n    x = torch.from_numpy(x).float()\n    y = torch.from_numpy(y).float()\n\n    for epoch in range(epochs):\n        # 前向传播\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        \n        # 反向传播和优化\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        if (epoch+1) % 10 == 0:\n            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n    print(\"Final Loss:\",loss.item())\n    # 在训练循环结束后\n    assert loss.item() < 2, \"Loss is not less than 2\"\n    return 1"}, {"question_id": 2, "language": "python", "file_name": "solution.py", "question": "import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n\nclass ImageClassifier(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(ImageClassifier, self).__init__()\n        self.conv = nn.Conv2d(input_size, 32, kernel_size=3, stride=1, padding=1)\n        self.fc = nn.Linear(32*32*32, num_classes)\n\n    def forward(self, x):\n        \"\"\"\n        输入:\n        - x: 一个形状为(batch_size, input_size, height, width)的PyTorch张量。\n\n        输出:\n        - out: 一个形状为(batch_size, num_classes)的PyTorch张量，表示图像分类模型的输出。\n        \"\"\"\n        \"\"\"\n        TODO:\n        1. 使用`self.conv`对输入`x`进行卷积操作。\n        2. 对卷积的结果进行ReLU激活函数操作。\n        3. 对激活函数的结果进行平均池化操作。\n        4. 将池化的结果展平(flatten)。\n        5. 使用`self.fc`对展平的结果进行线性变换。\n        6. 将线性变换的结果返回。\n\n         注意:\n        - 你应该使用`self.conv`和`self.fc`来进行计算。\n        - 不要使用任何形式的循环，包括for循环和while循环。\n        - 不要使用`.item()`，它会使得你的代码无法进行梯度反向传播。\n        \"\"\"", "reference": "import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\n\nclass ImageClassifier(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(ImageClassifier, self).__init__()\n        self.conv = nn.Conv2d(input_size, 32, kernel_size=3, stride=1, padding=1)\n        self.fc = nn.Linear(32*16*16, num_classes)\n\n    def forward(self, x):\n        \"\"\"\n        输入:\n        - x: 一个形状为(batch_size, input_size, height, width)的PyTorch张量。\n\n        输出:\n        - out: 一个形状为(batch_size, num_classes)的PyTorch张量，表示图像分类模型的输出。\n        \"\"\"\n         # 卷积操作\n        x = self.conv(x)\n        # ReLU激活函数\n        x = torch.relu(x)\n        # 平均池化操作\n        x = nn.functional.avg_pool2d(x, 2)\n        # 展平操作\n        x = x.view(x.size(0), -1)\n        # 线性变换\n        out = self.fc(x)\n        return out", "main": "import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.transforms as transforms\nfrom solution import ImageClassifier\ndef main():\n    # 定义超参数\n    input_size = 3  # 输入的维度（对于彩色图像，通常是3）\n    num_classes = 10  # 输出的维度（对于CIFAR-10数据集，有10个类别）\n    num_epochs = 3  # 训练的轮数\n    batch_size = 100  # 每个批次的样本数量\n    learning_rate = 0.001  # 学习率\n\n    # 加载CIFAR-10数据集\n    transform = transforms.Compose([transforms.ToTensor()])\n    train_dataset = torchvision.datasets.CIFAR10(root='./data/AItest/data', train=True, download=True, transform=transform)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\n    # 定义模型\n    model = ImageClassifier(input_size, num_classes)\n\n    # 定义损失函数和优化器\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n    # 训练模型\n    for epoch in range(num_epochs):\n        for i, (images, labels) in enumerate(train_loader):\n            # 前向传播\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            # 反向传播和优化\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            if (i+1) % 100 == 0:\n                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item()}')\n    print(\"最后的Loss:\",loss.item())\n    assert loss.item() < 2, \"Loss is not less than 2\"\n    return 1"}]